{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "2      1       1    0         1       0\n",
      "3      1       0    0         1       1\n",
      "4      0       1    1         0       1\n",
      "5      0       0    1         1       1\n",
      "6      0       0    0         1       1\n",
      "7      1       1    0         0       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# read dog dataset, No is encoded as 0, Yes as 1, \n",
    "# bite refers to class 1, bark to class 0\n",
    "\n",
    "training_data = pd.read_csv(\"dogs.csv\") \n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access individual columns by name to get a pandas series or convert it to a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    1\n",
      "Name: Heavy, dtype: int64\n",
      "[0 0 1 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(training_data[\"Heavy\"])\n",
    "print(training_data[\"Heavy\"].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the entropy of the target value 'Action' in the whole dataset? \n",
    "Define a function that calculates the entropy (for a list of 0/1 values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given solution\n",
    "def entropy(values):\n",
    "    base = len(values)\n",
    "    if base <= 1:\n",
    "            return 0 \n",
    "    \n",
    "    count0=sum([1 for i in values if i == 0])\n",
    "    count1=base-count0\n",
    "    p0=count0 / base\n",
    "    p1=count1 / base\n",
    "    \n",
    "    result = - (p0*math.log2(p0) if p0 > 0 else 0) - (p1*math.log2(p1) if p1 > 0 else 0)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#own solution\n",
    "def entropy(values):\n",
    "        # could be empty  while trying for a split\n",
    "        if values.size == 0:\n",
    "            return 0\n",
    "        \n",
    "        ratio_ones = sum(values) / len(values)\n",
    "        ratio_zeros = 1 - ratio_ones\n",
    "\n",
    "        pd = [ratio_ones, ratio_zeros]\n",
    "        if ratio_ones == 0 or ratio_zeros == 0:\n",
    "            return 0\n",
    "        return - sum( [ p_i * np.log2(p_i) for p_i in pd] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply it to the \"Action\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954434002924965\n"
     ]
    }
   ],
   "source": [
    "print(entropy(training_data[\"Action\"].to_numpy())) #Entropy of the target variable --> training entropy of the dataset before any splits are made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which attribute would the ID3 algorithm choose to use for the root of the tree? What is its information gain? \n",
    "\n",
    "Iterate through all categories, make the potential split, compare the resulting entropies and take the greedy choice. You might need:\n",
    "\n",
    "```\n",
    "# iterating the columns \n",
    "for col in data.columns: \n",
    "    print(col)\n",
    "```\n",
    "\n",
    "and to filter entries of a dataframe that satisfy a certain condition, you might want to use:\n",
    "```\n",
    "data[data[\"Heavy\"] == 0] # only those entries that are not heavy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heavy:0.0\n",
      "Heavy:0.0\n",
      "Smelly:0.0\n",
      "Smelly:0.0\n",
      "Big:0.0\n",
      "Big:0.0\n",
      "Growling:0.04556599707503495\n",
      "Growling:0.04556599707503495\n",
      "Action:0.0\n",
      "Action:0.0\n"
     ]
    }
   ],
   "source": [
    "for col in training_data.columns:\n",
    "    print(f'{col}:{entropy((training_data[col] == 0).to_numpy())-entropy(training_data[\"Action\"].to_numpy())}')\n",
    "    print(f'{col}:{entropy((training_data[col] == 1).to_numpy())-entropy(training_data[\"Action\"].to_numpy())}')\n",
    "#Results indicate Growling as the best Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Draw the full decision tree that would be learned for this data using ID3 without pruning.\n",
    "\n",
    "Recursively apply the splitting procedure until all nodes are leaf nodes (= pure in the target). You may use the class `Node` as a start for your implementation and attributes as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def entropy(self, values):\n",
    "        # could be empty  while trying for a split\n",
    "        if values.size == 0:\n",
    "            return 0\n",
    "        \n",
    "        ratio_ones = sum(values) / len(values)\n",
    "        ratio_zeros = 1 - ratio_ones\n",
    "\n",
    "        pd = [ratio_ones, ratio_zeros]\n",
    "        if ratio_ones == 0 or ratio_zeros == 0:\n",
    "            return 0\n",
    "        return - sum( [ p_i * np.log2(p_i) for p_i in pd] )\n",
    "    \n",
    "    def __init__(self, data, ancestor_features):\n",
    "        # pure if there are all ones or all zeros \n",
    "        self.pure = sum(data[\"Action\"]) == len(data) or  sum(data[\"Action\"]) == 0\n",
    "        self.split_feature = None\n",
    "        self.data = data\n",
    "        self.base_entropy = self.entropy(data[\"Action\"].to_numpy())\n",
    "        self.children = None\n",
    "        # since we're using categorical (binary), each features should at most be used once in any branch\n",
    "        self.ancestor_features = ancestor_features \n",
    "        # You can use these ancestor_features to get a nice identation:\n",
    "        # print(\" \"*len(self.ancestor_features) + f\"Initializing with data {data}\")\n",
    "        \n",
    "    def split(self):\n",
    "        # implement the split here\n",
    "        features = [col for col in self.data.columns if col not in self.ancestor_features and col != \"Action\"]\n",
    "        max_info_gain = -1\n",
    "        best_feature = None\n",
    "        \n",
    "        for feature in features:\n",
    "            for value in self.data[feature].unique():\n",
    "                subset = self.data[self.data[feature] == value]\n",
    "                entropy = self.entropy(subset[\"Action\"].to_numpy())\n",
    "                info_gain = self.base_entropy - entropy\n",
    "                \n",
    "                if info_gain > max_info_gain:\n",
    "                    max_info_gain = info_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = value\n",
    "        self.split_threshold = best_threshold\n",
    "        if best_feature is not None:\n",
    "            self.split_feature = best_feature\n",
    "            self.children = []\n",
    "            \n",
    "            for value in self.data[best_feature].unique():\n",
    "                subset = self.data[self.data[best_feature] == value]\n",
    "                child = Node(subset, self.ancestor_features + [best_feature])\n",
    "                self.children.append(child)\n",
    "    def train(self):        \n",
    "        if not self.pure:\n",
    "            self.split()\n",
    "            for child in self.children:\n",
    "                # assume that we can get nodes pure by looking at our features\n",
    "                # having exactly the same features but two different classes would not work here\n",
    "                child.train()\n",
    "                # now child is either pure or split into nodes that are eventually pure\n",
    "# start training with a root node consisting of all data\n",
    "    def predict(self, new_data):\n",
    "        if self.pure:\n",
    "            return self.data[\"Action\"].iloc[0]\n",
    "        else:\n",
    "            # Andernfalls entscheide anhand des geteilten Merkmals und Schwellenwerts\n",
    "            feature_value = new_data[self.split_feature]\n",
    "            if feature_value <= self.split_threshold:\n",
    "                # Wenn der Wert kleiner oder gleich dem Schwellenwert ist, gehe zum linken Kindknoten\n",
    "                return self.children[0].predict(new_data)\n",
    "            else:\n",
    "                # Andernfalls gehe zum rechten Kindknoten\n",
    "                return self.children[1].predict(new_data)\n",
    "root = Node(training_data, [])\n",
    "root.train()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "Der vorliegende Python-Code implementiert einen Entscheidungsbaum (Decision Tree) für binäre Klassifikation. Hier ist eine detaillierte Erklärung des Codes:\n",
    "\n",
    "1. Die Klasse `Node` stellt einen Knoten im Entscheidungsbaum dar. Jeder Knoten enthält eine Methode `entropy(values)`, die die Entropie für die gegebenen Klassenwerte berechnet. Die Entropie ist ein Maß für die Unreinheit der Klassenverteilung in einem Entscheidungsbaum. Niedrigere Entropie bedeutet, dass die Klassenverteilung homogener ist, während höhere Entropie auf eine gemischte Klassenverteilung hinweist.\n",
    "\n",
    "2. Im Konstruktor `__init__(self, data, ancestor_features)` werden die Attribute eines Knotens initialisiert. `data` ist der Datensatz, der von diesem Knoten repräsentiert wird, und `ancestor_features` ist eine Liste von Merkmalen, die von den Vorfahren dieses Knotens bereits verwendet wurden. Der Knoten wird als \"rein\" markiert, wenn alle Datenpunkte in `data` entweder zur Klasse \"1\" oder zur Klasse \"0\" gehören. Der Basis-Entropiewert für diesen Knoten wird mit der `entropy()`-Methode berechnet.\n",
    "\n",
    "3. Die `split()`-Methode implementiert die Spaltung des Knotens, um einen neuen Entscheidungszweig zu erstellen. Dazu wird das Merkmal mit dem höchsten Informationsgewinn (Information Gain) ausgewählt. Der Informationsgewinn wird berechnet, indem die Basisentropie des Knotens von der gewichteten Summe der entropie der nach der Spaltung entstehenden Teil-Datensätze abgezogen wird. Der beste Schwellenwert für das ausgewählte Merkmal wird ebenfalls gespeichert. Wenn ein Merkmal ausgewählt wird, werden die Kinderknoten mit neuen `Node`-Objekten erstellt und dem aktuellen Knoten als Kinder hinzugefügt.\n",
    "\n",
    "4. Die `train()`-Methode startet den Trainingsprozess des Entscheidungsbaums, indem sie den Baum rekursiv von der Wurzel (root) aus erstellt. Wenn der aktuelle Knoten nicht \"rein\" ist, wird die `split()`-Methode aufgerufen, um den Knoten zu spalten und den Trainingsprozess für die Kinderknoten fortzusetzen.\n",
    "\n",
    "5. Die `predict(new_data)`-Methode ermöglicht die Vorhersage von Klassenlabels für neue Datenpunkte basierend auf dem erstellten Entscheidungsbaum. Wenn der aktuelle Knoten \"rein\" ist, wird das Klassenlabel des Knotens zurückgegeben. Andernfalls wird das Merkmal des neuen Datenpunkts verwendet, um den entsprechenden Entscheidungszweig im Baum zu traversieren, indem der Schwellenwert des Merkmals mit dem Schwellenwert des aktuellen Knotens verglichen wird. Die Vorhersage wird rekursiv für die Kinderknoten fortgesetzt, bis ein \"reiner\" Knoten erreicht wird, dessen Klassenlabel zurückgegeben wird.\n",
    "\n",
    "6. `train(self)`: Diese Methode wird verwendet, um den Entscheidungsbaum zu trainieren. Sie beginnt mit dem Wurzelknoten (`self`) und überprüft, ob er bereits rein ist (`self.pure`). Wenn der Knoten nicht rein ist, wird der Split durchgeführt, indem die `split()`-Methode aufgerufen wird, um das beste Merkmal und den besten Schwellenwert für den Split zu finden. Dann wird für jedes Kind des aktuellen Knotens (`self.children`) die `train()`-Methode rekursiv aufgerufen, um den Trainingsprozess für die Kinder fortzusetzen. Dadurch wird der Entscheidungsbaum weiter aufgebaut, bis alle Blattknoten rein sind oder nicht weiter gesplittet werden können.\n",
    "\n",
    "7. `predict(self, new_data)`: Diese Methode wird verwendet, um Vorhersagen für neue Daten zu treffen. Sie beginnt beim Wurzelknoten (`self`) und überprüft, ob der Knoten rein ist (`self.pure`). Wenn ja, wird das vorhersagte Label aus dem `data`-Attribut des Knotens zurückgegeben. Andernfalls wird das Merkmal und der Schwellenwert des aktuellen Knotens verwendet, um zu entscheiden, ob der linke oder der rechte Kindknoten für die Vorhersage verwendet werden soll. Dieser Prozess wird rekursiv für das entsprechende Kind fortgesetzt, bis ein Blattknoten erreicht wird, dessen vorhergesagtes Label zurückgegeben wird.\n",
    "\n",
    "8. Schließlich wird ein `Node`-Objekt namens `root` erstellt, das mit den Trainingsdaten und einer leeren Liste von Vorgänger-Merkmalen initialisiert wird. Die `train()`-Methode wird auf `root` aufgerufen, um den Entscheidungsbaum zu trainieren und den Baum aufzubauen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on three new dogs\n",
    "Here's the test set, evaluate the predicted \"Action\" classes using your implementation and compare them to the true \"Action\" classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]\n",
      " [0 0 0 1 0]\n",
      " [1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "temp_data = np.array(pd.read_csv(\"dogs_test.csv\"))\n",
    "print(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:0\n",
      "Prediction:0\n",
      "Prediction:1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data = [{\"Heavy\":1,\"Smelly\":0,\"Big\":1,\"Growling\":1}, {\"Heavy\": 0, \"Smelly\": 0, \"Big\": 0, \"Growling\": 1},{\"Heavy\": 1, \"Smelly\": 1, \"Big\": 0, \"Growling\": 0}]\n",
    "for data_point in test_data:\n",
    "    print(\"Prediction:\"+ str(root.predict(data_point)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat with the Gini coefficient\n",
    "Just alter your previous implementations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46875\n"
     ]
    }
   ],
   "source": [
    "#defining and testing gini function\n",
    "def gini(values):\n",
    "    base=len(values)\n",
    "    if values.size == 0:\n",
    "        return 0\n",
    "    count0=sum([1 for i in values if i == 0])\n",
    "    count1=base-count0\n",
    "    p0=count0 / base\n",
    "    p1=count1 / base\n",
    "    result = 1-(p0**2+p1**2)\n",
    "    return result\n",
    "    \n",
    "print(gini(training_data[\"Action\"].to_numpy())) #0.46875 confirmed by calculator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "2      1       1    0         1       0\n",
      "3      1       0    0         1       1\n",
      "4      0       1    1         0       1\n",
      "5      0       0    1         1       1\n",
      "6      0       0    0         1       1\n",
      "7      1       1    0         0       1\n",
      "    Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "4      0       1    1         0       1\n",
      "7      1       1    0         0       1\n",
      "    Heavy  Smelly  Big  Growling  Action\n",
      "2      1       1    0         1       0\n",
      "3      1       0    0         1       1\n",
      "5      0       0    1         1       1\n",
      "6      0       0    0         1       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "4      0       1    1         0       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "7      1       1    0         0       1\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "4      0       1    1         0       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "2      1       1    0         1       0\n",
      "3      1       0    0         1       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "5      0       0    1         1       1\n",
      "6      0       0    0         1       1\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "2      1       1    0         1       0\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "3      1       0    0         1       1\n"
     ]
    }
   ],
   "source": [
    "#rewriting class with gini instead of entropy\n",
    "class Node:\n",
    "    \n",
    "    def gini(self,values):\n",
    "        base=len(values)\n",
    "        if values.size == 0:\n",
    "            return 0\n",
    "        count0=sum([1 for i in values if i == 0])\n",
    "        count1=base-count0\n",
    "        p0=count0 / base\n",
    "        p1=count1 / base\n",
    "        result = 1-(p0**2+p1**2)\n",
    "        return result\n",
    "    \n",
    "    def __init__(self, data, ancestor_features):\n",
    "        # pure if there are all ones or all zeros \n",
    "        self.pure = sum(data[\"Action\"]) == len(data) or  sum(data[\"Action\"]) == 0\n",
    "        self.split_feature = None\n",
    "        self.data = data\n",
    "        self.base_gini = self.gini(data[\"Action\"].to_numpy())\n",
    "        self.children = None\n",
    "        # since we're using categorical (binary), each features should at most be used once in any branch\n",
    "        self.ancestor_features = ancestor_features \n",
    "        # You can use these ancestor_features to get a nice identation:\n",
    "        print(\" \"*len(self.ancestor_features) + f\"{data}\")\n",
    "        \n",
    "    def split(self):\n",
    "        # implement the split here\n",
    "        features = [col for col in self.data.columns if col not in self.ancestor_features and col != \"Action\"]\n",
    "        max_info_gain = -1\n",
    "        best_feature = None\n",
    "        \n",
    "        for feature in features:\n",
    "            for value in self.data[feature].unique():\n",
    "                subset = self.data[self.data[feature] == value]\n",
    "                gini = self.gini(subset[\"Action\"].to_numpy())\n",
    "                info_gain = self.base_gini - gini\n",
    "                \n",
    "                if info_gain > max_info_gain:\n",
    "                    max_info_gain = info_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = value\n",
    "        self.split_threshold = best_threshold\n",
    "        if best_feature is not None:\n",
    "            self.split_feature = best_feature\n",
    "            self.children = []\n",
    "            \n",
    "            for value in self.data[best_feature].unique():\n",
    "                subset = self.data[self.data[best_feature] == value]\n",
    "                child = Node(subset, self.ancestor_features + [best_feature])\n",
    "                self.children.append(child)\n",
    "    def train(self):        \n",
    "        if not self.pure:\n",
    "            self.split()\n",
    "            for child in self.children:\n",
    "                # assume that we can get nodes pure by looking at our features\n",
    "                # having exactly the same features but two different classes would not work here\n",
    "                child.train()\n",
    "                # now child is either pure or split into nodes that are eventually pure\n",
    "# start training with a root node consisting of all data\n",
    "    def predict(self, new_data):\n",
    "        if self.pure:\n",
    "            return self.data[\"Action\"].iloc[0]\n",
    "        else:\n",
    "            # Andernfalls entscheide anhand des geteilten Merkmals und Schwellenwerts\n",
    "            feature_value = new_data[self.split_feature]\n",
    "            if feature_value <= self.split_threshold:\n",
    "                # Wenn der Wert kleiner oder gleich dem Schwellenwert ist, gehe zum linken Kindknoten\n",
    "                return self.children[0].predict(new_data)\n",
    "            else:\n",
    "                # Andernfalls gehe zum rechten Kindknoten\n",
    "                return self.children[1].predict(new_data)\n",
    "root_gini = Node(training_data, [])\n",
    "root_gini.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:0\n",
      "Prediction:0\n",
      "Prediction:1\n"
     ]
    }
   ],
   "source": [
    "for data_point in test_data:\n",
    "    print(\"Prediction:\"+ str(root_gini.predict(data_point)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Labex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
