{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYrevNWp-o0p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUlZmmLJ-o1H"
      },
      "source": [
        "# Let's work on classifying fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF3sAc-C-o1W"
      },
      "outputs": [],
      "source": [
        "# load the dataset (keras offers a functionality for this)\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = (fashion_mnist.load_data())\n",
        "\n",
        "# okay we need better names for that:\n",
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "# get a validation set of size 5000\n",
        "# use the train-test split of scikit-learn for that matter\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=5000, random_state=42)\n",
        "\n",
        "# normalize input data to lie between 0 and 1\n",
        "X_train = X_train/ 255.\n",
        "X_val = X_val / 255.\n",
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtCJ4mSF-o1-"
      },
      "outputs": [],
      "source": [
        "# Data visualization\n",
        "n_rows = 2\n",
        "n_cols = 8\n",
        "plt.figure(figsize=(n_cols*1.6, n_rows*1.8))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_train[index]])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2E1gSqF-o2Y"
      },
      "source": [
        "# Feedforward Neural network in Keras\n",
        "Now it's time to shine for the neural network powered by keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8JlVFN8-o2Z"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, input_shape=[28*28], activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "model.summary()\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history_ReLU = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))\n",
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(history_ReLU.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt52CHXMyhkT"
      },
      "source": [
        "# Compare ReLU activation to Sigmoid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AUIwlB9yznb"
      },
      "outputs": [],
      "source": [
        "# TODO use sigmoid instead of relu\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, input_shape=[28*28], activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "model.summary()\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history_sigmoid = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))\n",
        "pd.DataFrame(history_sigmoid.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGpI0SfJzaRR"
      },
      "source": [
        "# And now tanh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpcnVD3Kzff5"
      },
      "outputs": [],
      "source": [
        "# TODO use tanh instead of relu\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "model.add(keras.layers.Dense(300, input_shape=[28*28], activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "model.summary()\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history_tanh = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))\n",
        "pd.DataFrame(history_tanh.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ter2IEEKwN7U"
      },
      "outputs": [],
      "source": [
        "# Data visualization\n",
        "n_rows = 3\n",
        "n_cols = 1\n",
        "histories = [[history_ReLU], [history_sigmoid], [history_tanh]]\n",
        "titles = [[\"ReLU\"], [\"Sigmoid\"], [\"Tanh\"]]\n",
        "\n",
        "col_width = 6.6\n",
        "row_height = 4\n",
        "plt.figure(figsize=(n_cols*col_width, n_rows*row_height))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        ax = plt.subplot(n_rows, n_cols, index + 1)\n",
        "        history = histories[row][col]\n",
        "        title = titles[row][col]\n",
        "        pd.DataFrame(history.history).plot(ax=ax)\n",
        "        #plt.axis('off')\n",
        "        plt.title(title)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Fashion_MNIST_hyperparams.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
