{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "2      1       1    0         1       0\n",
      "3      1       0    0         1       1\n",
      "4      0       1    1         0       1\n",
      "5      0       0    1         1       1\n",
      "6      0       0    0         1       1\n",
      "7      1       1    0         0       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# read dog dataset, No is encoded as 0, Yes as 1, \n",
    "# bite refers to class 1, bark to class 0\n",
    "\n",
    "data = pd.read_csv(\"dogs.csv\") \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access individual columns by name to get a pandas series or convert it to a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    1\n",
      "Name: Heavy, dtype: int64\n",
      "[0 0 1 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(data[\"Heavy\"])\n",
    "print(data[\"Heavy\"].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the entropy of the target value 'Action' in the whole dataset? \n",
    "Define a function that calculates the entropy (for a list of 0/1 values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(values):\n",
    "    base = len(values)\n",
    "    if base <= 1:\n",
    "            return 0 \n",
    "    \n",
    "    count0=sum([1 for i in values if i == 0])\n",
    "    count1=base-count0\n",
    "    p0=count0 / base\n",
    "    p1=count1 / base\n",
    "    \n",
    "    result = - (p0*math.log2(p0) if p0 > 0 else 0) - (p1*math.log2(p1) if p1 > 0 else 0)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(values):\n",
    "        # could be empty  while trying for a split\n",
    "        if values.size == 0:\n",
    "            return 0\n",
    "        \n",
    "        ratio_ones = sum(values) / len(values)\n",
    "        ratio_zeros = 1 - ratio_ones\n",
    "\n",
    "        pd = [ratio_ones, ratio_zeros]\n",
    "        if ratio_ones == 0 or ratio_zeros == 0:\n",
    "            return 0\n",
    "        return - sum( [ p_i * np.log2(p_i) for p_i in pd] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply it to the \"Action\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954434002924965\n"
     ]
    }
   ],
   "source": [
    "print(entropy(data[\"Action\"].to_numpy())) #Entropy of the target variable --> inital entropy of the dataset before any splits are made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which attribute would the ID3 algorithm choose to use for the root of the tree? What is its information gain? \n",
    "\n",
    "Iterate through all categories, make the potential split, compare the resulting entropies and take the greedy choice. You might need:\n",
    "\n",
    "```\n",
    "# iterating the columns \n",
    "for col in data.columns: \n",
    "    print(col)\n",
    "```\n",
    "\n",
    "and to filter entries of a dataframe that satisfy a certain condition, you might want to use:\n",
    "```\n",
    "data[data[\"Heavy\"] == 0] # only those entries that are not heavy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heavy:0.0\n",
      "Heavy:0.0\n",
      "Smelly:0.0\n",
      "Smelly:0.0\n",
      "Big:0.0\n",
      "Big:0.0\n",
      "Growling:0.04556599707503495\n",
      "Growling:0.04556599707503495\n",
      "Action:0.0\n",
      "Action:0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in data.columns:\n",
    "    print(f'{col}:{entropy((data[col] == 0).to_numpy())-entropy(data[\"Action\"].to_numpy())}')\n",
    "    print(f'{col}:{entropy((data[col] == 1).to_numpy())-entropy(data[\"Action\"].to_numpy())}')\n",
    "#Results indicate Growling as the best Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Draw the full decision tree that would be learned for this data using ID3 without pruning.\n",
    "\n",
    "Recursively apply the splitting procedure until all nodes are leaf nodes (= pure in the target). You may use the class `Node` as a start for your implementation and attributes as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def entropy(self, values):\n",
    "        # could be empty  while trying for a split\n",
    "        if values.size == 0:\n",
    "            return 0\n",
    "        \n",
    "        ratio_ones = sum(values) / len(values)\n",
    "        ratio_zeros = 1 - ratio_ones\n",
    "\n",
    "        pd = [ratio_ones, ratio_zeros]\n",
    "        if ratio_ones == 0 or ratio_zeros == 0:\n",
    "            return 0\n",
    "        return - sum( [ p_i * np.log2(p_i) for p_i in pd] )\n",
    "    \n",
    "    def __init__(self, data, ancestor_features):\n",
    "        # pure if there are all ones or all zeros \n",
    "        self.pure = sum(data[\"Action\"]) == len(data) or  sum(data[\"Action\"]) == 0\n",
    "        self.split_feature = None\n",
    "        self.data = data\n",
    "        self.base_entropy = self.entropy(data[\"Action\"].to_numpy())\n",
    "        self.children = None\n",
    "        # since we're using categorical (binary), each features should at most be used once in any branch\n",
    "        self.ancestor_features = ancestor_features \n",
    "        # You can use these ancestor_features to get a nice identation:\n",
    "        # print(\" \"*len(self.ancestor_features) + f\"Initializing with data {data}\")\n",
    "        \n",
    "    def split(self):\n",
    "        # implement the split here\n",
    "        features = [col for col in self.data.columns if col not in self.ancestor_features and col != \"Action\"]\n",
    "        max_info_gain = -1\n",
    "        best_feature = None\n",
    "        \n",
    "        for feature in features:\n",
    "            for value in self.data[feature].unique():\n",
    "                subset = self.data[self.data[feature] == value]\n",
    "                entropy = self.entropy(subset[\"Action\"].to_numpy())\n",
    "                info_gain = self.base_entropy - entropy\n",
    "                \n",
    "                if info_gain > max_info_gain:\n",
    "                    max_info_gain = info_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = value\n",
    "        self.split_threshold = best_threshold\n",
    "        if best_feature is not None:\n",
    "            self.split_feature = best_feature\n",
    "            self.children = []\n",
    "            \n",
    "            for value in self.data[best_feature].unique():\n",
    "                subset = self.data[self.data[best_feature] == value]\n",
    "                child = Node(subset, self.ancestor_features + [best_feature])\n",
    "                self.children.append(child)\n",
    "    def train(self):        \n",
    "        if not self.pure:\n",
    "            self.split()\n",
    "            for child in self.children:\n",
    "                # assume that we can get nodes pure by looking at our features\n",
    "                # having exactly the same features but two different classes would not work here\n",
    "                child.train()\n",
    "                # now child is either pure or split into nodes that are eventually pure\n",
    "# start training with a root node consisting of all data\n",
    "    def predict(self, new_data):\n",
    "        if self.pure:\n",
    "            return self.data[\"Action\"].iloc[0]\n",
    "        else:\n",
    "            # Andernfalls entscheide anhand des geteilten Merkmals und Schwellenwerts\n",
    "            feature_value = new_data[self.split_feature]\n",
    "            if feature_value <= self.split_threshold:\n",
    "                # Wenn der Wert kleiner oder gleich dem Schwellenwert ist, gehe zum linken Kindknoten\n",
    "                return self.children[0].predict(new_data)\n",
    "            else:\n",
    "                # Andernfalls gehe zum rechten Kindknoten\n",
    "                return self.children[1].predict(new_data)\n",
    "root = Node(data, [])\n",
    "root.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on three new dogs\n",
    "Here's the test set, evaluate the predicted \"Action\" classes using your implementation and compare them to the true \"Action\" classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:0\n",
      "Prediction:0\n",
      "Prediction:1\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"dogs_test.csv\").to_numpy()\n",
    "\n",
    "data = [{\"Heavy\":1,\"Smelly\":0,\"Big\":1,\"Growling\":1}, {\"Heavy\": 0, \"Smelly\": 0, \"Big\": 0, \"Growling\": 1},{\"Heavy\": 1, \"Smelly\": 1, \"Big\": 0, \"Growling\": 0}]\n",
    "for data_point in data:\n",
    "    print(\"Prediction:\"+ str(root.predict(data_point)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat with the Gini coefficient\n",
    "Just alter your previous implementations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimaEnv",
   "language": "python",
   "name": "aimaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
