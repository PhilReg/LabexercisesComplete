{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 01 - Exercise 1\n",
    "\n",
    "Implement a function linearThresholdUnit that takes a list of x-values and a list of wvalues,calculates the weighted sum and returns 1 if that sum is greater than or equal – otherwise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearThresholdUnit(x_values,w_values):\n",
    "    weightedsum = sum(x*w for x,w in zip(x_values,w_values))\n",
    "    if weightedsum > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "x = [1,0,1]\n",
    "w=[2,-2,-1]\n",
    "print(linearThresholdUnit(x,w))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 02 - Exercise 2\n",
    "\n",
    "Implement the spam detection classifier (slide 29 in ”Lecture 1 - Introduction”) in Python. You can do this by following the steps below:\n",
    "-Transfer the data set on slide 29 into an appropiate Python data structure\n",
    "-Implement the classifier on slide 29 that takes into account the three features “Occurences Bank”, “Occurences 1 000 000” and “Occurences Best regards”. For each input, the output should be either “True” or “False”. \n",
    "Hint: You may be able to reuse some of the code you already implemented in assignment 1.\n",
    "-Write Python to calculate the accuracy of the clasifier’s predictions.\n",
    "-Play around with different weights and see if you can further improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:1 --> Spam \n",
      " Correct\n",
      "Value:0 --> Spam \n",
      " Correct\n",
      "Value:-2 --> no Spam \n",
      " Correct\n",
      "Value:-3 --> no Spam \n",
      " Correct\n",
      "Value:-1 --> no Spam \n",
      " Correct\n",
      "The accuracy of the classifier is at 100.0%\n"
     ]
    }
   ],
   "source": [
    "datadic = {\"dataset1\":[1,0,1],\"dataset2\":[1,0,2],\"dataset3\":[1,2,0],\"dataset4\":[0,1,1],\"dataset5\":[0,0,1]}\n",
    "resultdic = {\"dataset1\":[\"True\"],\"dataset2\":[\"True\"],\"dataset3\":[\"False\"],\"dataset4\":[\"False\"],\"dataset5\":[\"False\"]}\n",
    "weights = [2,-2,-1]\n",
    "\n",
    "t=0\n",
    "f=0\n",
    "\n",
    "def relu_function(x, w):\n",
    "    relu = sum(xi * wi for xi, wi in zip(x, w))\n",
    "    return relu\n",
    "\n",
    "for key in datadic:\n",
    "    value= relu_function(datadic[key], weights)\n",
    "    result = resultdic[key][0]\n",
    "    if value >= 0 and result == \"True\":\n",
    "        print(f\"Value:{value} --> Spam \\n Correct\")\n",
    "        t+=1\n",
    "    elif value >= 0 and result == \"False\":\n",
    "        print(f\"Value:{value} --> Spam \\n False\")\n",
    "        f+=1\n",
    "    elif value <= 0 and result == \"False\":\n",
    "        print(f\"Value:{value} --> no Spam \\n Correct\")\n",
    "        t+=1\n",
    "    elif value <= 0 and result == \"True\":\n",
    "        print(f\"Value:{value} --> no Spam \\n False\")\n",
    "        f+=1\n",
    "\n",
    "accuracy = t/(t+f)*100\n",
    "print(f\"The accuracy of the classifier is at {accuracy}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 03 - Exercise 1\n",
    "Take another look at exercise 1 of assignment 2. In this exercise, your task was to implement the spam detection model from the lecture using Python. Since you are now familiar with NumPy, try to substitute as much of the pure Python code with improved NumPy code. Place special focus on lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = [[1,0,1],[1,0,2],[1,2,0],[0,1,1],[0,0,1]]\n",
    "weights = [2,-2,-1]\n",
    "labels = [True,True,False,False,False]\n",
    "\n",
    "sums = np.sum(np.multiply(data,weights),axis=1)\n",
    "results = sums >= 0\n",
    "matches = np.sum(results == labels)\n",
    "\n",
    "print(f\"Accuracy: {matches/len(data)*100}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 04 - Exercise 2\n",
    "Imagine you are a newspaper deliverer that encounters a number of dogs on your tour. Some of them (try to) bite, some of then only bark. The dogs are described by the following binary features: Heavy, Smelly, Big and Growling. Consider the following set of examples:\n",
    "| Heavy | Smelly | Big | Growling | Action |\n",
    "|----------|----------|----------|----------|----------|\n",
    "| No | No | No | No | Bark |\n",
    "| No | No | Yes | No | Bark |\n",
    "| Yes | Yes | No | Yes | Bark |\n",
    "| Yes | No | No | Yes | Bite |\n",
    "| No | Yes | Yes | No | Bite |\n",
    "| No | No | Yes | Yes | Bite |\n",
    "| No | No | No | Yes | Bite |\n",
    "| Yes | Yes | No | No | Bite |\n",
    "\n",
    "Round all values within this exercise back to 4 decimal places. Note that we’ve prepared the\n",
    "dataset as a NumPy array in dogtree.ipynb. You may use this notebook for your calculations or\n",
    "work out the answers manually – depending on your liking.\n",
    "\n",
    "\n",
    "### Fullsolution in Assignment04 dogtree.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task a) What is the entropy of the target value ’Action’ in the whole dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954434002924965\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# read dog dataset, No is encoded as 0, Yes as 1, \n",
    "# bite refers to class 1, bark to class 0\n",
    "\n",
    "training_data = pd.read_csv(\"Assignment04\\dogs.csv\") \n",
    "def entropy(values):\n",
    "        # could be empty  while trying for a split\n",
    "        if values.size == 0:\n",
    "            return 0\n",
    "        \n",
    "        ratio_ones = sum(values) / len(values)\n",
    "        ratio_zeros = 1 - ratio_ones\n",
    "\n",
    "        pd = [ratio_ones, ratio_zeros]\n",
    "        if ratio_ones == 0 or ratio_zeros == 0:\n",
    "            return 0\n",
    "        return - sum( [ p_i * np.log2(p_i) for p_i in pd] )\n",
    "print(entropy(training_data[\"Action\"].to_numpy()))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropy for Action: 0.9544"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task b) Which attribute would the ID3 algorithm choose to use for the root of the tree? What is its information gain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.04556599707503495, 'Growling')\n"
     ]
    }
   ],
   "source": [
    "igains =[]\n",
    "attributes = []\n",
    "for col in training_data.columns:\n",
    "    igains.append(entropy((training_data[col] == 0).to_numpy())-entropy(training_data[\"Action\"].to_numpy()))\n",
    "    attributes.append(col)\n",
    "print(max(zip(igains,attributes)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --> Growling, information gain = 0.0455"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task c) Draw the full decision tree that would be learned for this data using ID3 without pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "2      1       1    0         1       0\n",
      "3      1       0    0         1       1\n",
      "4      0       1    1         0       1\n",
      "5      0       0    1         1       1\n",
      "6      0       0    0         1       1\n",
      "7      1       1    0         0       1\n",
      "    Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "4      0       1    1         0       1\n",
      "7      1       1    0         0       1\n",
      "    Heavy  Smelly  Big  Growling  Action\n",
      "2      1       1    0         1       0\n",
      "3      1       0    0         1       1\n",
      "5      0       0    1         1       1\n",
      "6      0       0    0         1       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "4      0       1    1         0       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "7      1       1    0         0       1\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "4      0       1    1         0       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "2      1       1    0         1       0\n",
      "3      1       0    0         1       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "5      0       0    1         1       1\n",
      "6      0       0    0         1       1\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "2      1       1    0         1       0\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "3      1       0    0         1       1\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    \n",
    "    def entropy(self, values):\n",
    "        # could be empty  while trying for a split\n",
    "        if values.size == 0:\n",
    "            return 0\n",
    "        \n",
    "        ratio_ones = sum(values) / len(values)\n",
    "        ratio_zeros = 1 - ratio_ones\n",
    "\n",
    "        pd = [ratio_ones, ratio_zeros]\n",
    "        if ratio_ones == 0 or ratio_zeros == 0:\n",
    "            return 0\n",
    "        return - sum( [ p_i * np.log2(p_i) for p_i in pd] )\n",
    "    \n",
    "    def __init__(self, data, ancestor_features):\n",
    "        # pure if there are all ones or all zeros \n",
    "        self.pure = sum(data[\"Action\"]) == len(data) or  sum(data[\"Action\"]) == 0\n",
    "        self.split_feature = None\n",
    "        self.data = data\n",
    "        self.base_entropy = self.entropy(data[\"Action\"].to_numpy())\n",
    "        self.children = None\n",
    "        # since we're using categorical (binary), each features should at most be used once in any branch\n",
    "        self.ancestor_features = ancestor_features \n",
    "        # You can use these ancestor_features to get a nice identation:\n",
    "        print(\" \"*len(self.ancestor_features) + f\"{data}\")\n",
    "        \n",
    "    def split(self):\n",
    "        # implement the split here\n",
    "        features = [col for col in self.data.columns if col not in self.ancestor_features and col != \"Action\"]\n",
    "        max_info_gain = -1\n",
    "        best_feature = None\n",
    "        \n",
    "        for feature in features:\n",
    "            for value in self.data[feature].unique():\n",
    "                subset = self.data[self.data[feature] == value]\n",
    "                entropy = self.entropy(subset[\"Action\"].to_numpy())\n",
    "                info_gain = self.base_entropy - entropy\n",
    "                \n",
    "                if info_gain > max_info_gain:\n",
    "                    max_info_gain = info_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = value\n",
    "        self.split_threshold = best_threshold\n",
    "        if best_feature is not None:\n",
    "            self.split_feature = best_feature\n",
    "            self.children = []\n",
    "            \n",
    "            for value in self.data[best_feature].unique():\n",
    "                subset = self.data[self.data[best_feature] == value]\n",
    "                child = Node(subset, self.ancestor_features + [best_feature])\n",
    "                self.children.append(child)\n",
    "    def train(self):        \n",
    "        if not self.pure:\n",
    "            self.split()\n",
    "            for child in self.children:\n",
    "                # assume that we can get nodes pure by looking at our features\n",
    "                # having exactly the same features but two different classes would not work here\n",
    "                child.train()\n",
    "                # now child is either pure or split into nodes that are eventually pure\n",
    "# start training with a root node consisting of all data\n",
    "    def predict(self, new_data):\n",
    "        if self.pure:\n",
    "            return self.data[\"Action\"].iloc[0]\n",
    "        else:\n",
    "            # Andernfalls entscheide anhand des geteilten Merkmals und Schwellenwerts\n",
    "            feature_value = new_data[self.split_feature]\n",
    "            if feature_value <= self.split_threshold:\n",
    "                # Wenn der Wert kleiner oder gleich dem Schwellenwert ist, gehe zum linken Kindknoten\n",
    "                return self.children[0].predict(new_data)\n",
    "            else:\n",
    "                # Andernfalls gehe zum rechten Kindknoten\n",
    "                return self.children[1].predict(new_data)\n",
    "root = Node(training_data, [])\n",
    "root.train()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task d) Suppose three new dogs appear in your round as listed in the table below. Classify them using the decision tree from the previous question. \n",
    "#### What is the accuracy of your tree on this test set?\n",
    "\n",
    "| Name | Heavy | Smelly | Big | Growling | Action |\n",
    "|----------|----------|----------|----------|----------|----------|\n",
    "| Buster | Yes | No | Yes | Yes | Bark |\n",
    "| Pluto | No | No | No | Yes | Bark |\n",
    "| Zeus | Yes | Yes | No | No | Bite |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:0\n",
      "Prediction:0\n",
      "Prediction:1\n"
     ]
    }
   ],
   "source": [
    "test_data = [{\"Heavy\":1,\"Smelly\":0,\"Big\":1,\"Growling\":1}, {\"Heavy\": 0, \"Smelly\": 0, \"Big\": 0, \"Growling\": 1},{\"Heavy\": 1, \"Smelly\": 1, \"Big\": 0, \"Growling\": 0}]\n",
    "for data_point in test_data:\n",
    "    print(\"Prediction:\"+ str(root.predict(data_point)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --> 100% Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task e) Repeat the steps of the previous four subtasks using the Gini coefficient as splitting criteria.\n",
    "#### Are there differences between the resulting trees and their performance on the above test set? Think about the reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "2      1       1    0         1       0\n",
      "3      1       0    0         1       1\n",
      "4      0       1    1         0       1\n",
      "5      0       0    1         1       1\n",
      "6      0       0    0         1       1\n",
      "7      1       1    0         0       1\n",
      "    Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "4      0       1    1         0       1\n",
      "7      1       1    0         0       1\n",
      "    Heavy  Smelly  Big  Growling  Action\n",
      "2      1       1    0         1       0\n",
      "3      1       0    0         1       1\n",
      "5      0       0    1         1       1\n",
      "6      0       0    0         1       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "4      0       1    1         0       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "7      1       1    0         0       1\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "0      0       0    0         0       0\n",
      "1      0       0    1         0       0\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "4      0       1    1         0       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "2      1       1    0         1       0\n",
      "3      1       0    0         1       1\n",
      "     Heavy  Smelly  Big  Growling  Action\n",
      "5      0       0    1         1       1\n",
      "6      0       0    0         1       1\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "2      1       1    0         1       0\n",
      "      Heavy  Smelly  Big  Growling  Action\n",
      "3      1       0    0         1       1\n"
     ]
    }
   ],
   "source": [
    "#rewriting class with gini instead of entropy\n",
    "class Node:\n",
    "    \n",
    "    def gini(self,values):\n",
    "        base=len(values)\n",
    "        if values.size == 0:\n",
    "            return 0\n",
    "        count0=sum([1 for i in values if i == 0])\n",
    "        count1=base-count0\n",
    "        p0=count0 / base\n",
    "        p1=count1 / base\n",
    "        result = 1-(p0**2+p1**2)\n",
    "        return result\n",
    "    \n",
    "    def __init__(self, data, ancestor_features):\n",
    "        # pure if there are all ones or all zeros \n",
    "        self.pure = sum(data[\"Action\"]) == len(data) or  sum(data[\"Action\"]) == 0\n",
    "        self.split_feature = None\n",
    "        self.data = data\n",
    "        self.base_gini = self.gini(data[\"Action\"].to_numpy())\n",
    "        self.children = None\n",
    "        # since we're using categorical (binary), each features should at most be used once in any branch\n",
    "        self.ancestor_features = ancestor_features \n",
    "        # You can use these ancestor_features to get a nice identation:\n",
    "        print(\" \"*len(self.ancestor_features) + f\"{data}\")\n",
    "        \n",
    "    def split(self):\n",
    "        # implement the split here\n",
    "        features = [col for col in self.data.columns if col not in self.ancestor_features and col != \"Action\"]\n",
    "        max_info_gain = -1\n",
    "        best_feature = None\n",
    "        \n",
    "        for feature in features:\n",
    "            for value in self.data[feature].unique():\n",
    "                subset = self.data[self.data[feature] == value]\n",
    "                gini = self.gini(subset[\"Action\"].to_numpy())\n",
    "                info_gain = self.base_gini - gini\n",
    "                \n",
    "                if info_gain > max_info_gain:\n",
    "                    max_info_gain = info_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = value\n",
    "        self.split_threshold = best_threshold\n",
    "        if best_feature is not None:\n",
    "            self.split_feature = best_feature\n",
    "            self.children = []\n",
    "            \n",
    "            for value in self.data[best_feature].unique():\n",
    "                subset = self.data[self.data[best_feature] == value]\n",
    "                child = Node(subset, self.ancestor_features + [best_feature])\n",
    "                self.children.append(child)\n",
    "    def train(self):        \n",
    "        if not self.pure:\n",
    "            self.split()\n",
    "            for child in self.children:\n",
    "                # assume that we can get nodes pure by looking at our features\n",
    "                # having exactly the same features but two different classes would not work here\n",
    "                child.train()\n",
    "                # now child is either pure or split into nodes that are eventually pure\n",
    "# start training with a root node consisting of all data\n",
    "    def predict(self, new_data):\n",
    "        if self.pure:\n",
    "            return self.data[\"Action\"].iloc[0]\n",
    "        else:\n",
    "            # Andernfalls entscheide anhand des geteilten Merkmals und Schwellenwerts\n",
    "            feature_value = new_data[self.split_feature]\n",
    "            if feature_value <= self.split_threshold:\n",
    "                # Wenn der Wert kleiner oder gleich dem Schwellenwert ist, gehe zum linken Kindknoten\n",
    "                return self.children[0].predict(new_data)\n",
    "            else:\n",
    "                # Andernfalls gehe zum rechten Kindknoten\n",
    "                return self.children[1].predict(new_data)\n",
    "root_gini = Node(training_data, [])\n",
    "root_gini.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:0\n",
      "Prediction:0\n",
      "Prediction:1\n"
     ]
    }
   ],
   "source": [
    "for data_point in test_data:\n",
    "    print(\"Prediction:\"+ str(root_gini.predict(data_point)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --> 100% Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
